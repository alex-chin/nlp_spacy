{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Конвейер обработки текста"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fc672c265175af9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Настройка рабочей среды"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "707295d5e43d1573"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-28T14:51:26.502958800Z",
     "start_time": "2023-11-28T14:51:22.229643400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m\n",
      "============================== Info about spaCy ==============================\u001B[0m\n",
      "\n",
      "spaCy version    3.7.2                         \n",
      "Location         C:\\prj\\nlp_spacy\\venv\\Lib\\site-packages\\spacy\n",
      "Platform         Windows-10-10.0.22621-SP0     \n",
      "Python version   3.11.4                        \n",
      "Pipelines        en_core_web_sm (3.7.1), ru_core_news_sm (3.7.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "#!python -m spacy download en"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f31cfd909c3643b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use\n",
    "the full pipeline package name 'en_core_web_sm' instead."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dd466b2c28302f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63d3b2cdb0b8cd6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can now load the package via spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cab70606b75ddb4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !python -m spacy download ru_core_news_sm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cfd72d9e07fa5a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can now load the package via spacy.load('ru_core_news_sm')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "796e3e69eb7e7ed1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Загрузка корпуса"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a17cd1afa634f92"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T14:53:10.959986300Z",
     "start_time": "2023-11-28T14:53:10.441931500Z"
    }
   },
   "id": "d84771037c90e3c2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "nlp_ru = spacy.load('ru_core_news_sm')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T14:53:13.309643Z",
     "start_time": "2023-11-28T14:53:11.851166500Z"
    }
   },
   "id": "81f8e2bcdc6a1ee5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Токенизация"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3140510eeda62c7c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'flying', 'to', 'Frisco']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_en(u'I am flying to Frisco')\n",
    "print([w.text for w in doc])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:20:25.966241300Z",
     "start_time": "2023-11-26T20:20:25.948239900Z"
    }
   },
   "id": "cca59066ada8699c"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Я', 'лечу', 'в', 'Казань']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_ru(u'Я лечу в Казань')\n",
    "print([w.text for w in doc])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:20:27.034067100Z",
     "start_time": "2023-11-26T20:20:26.977432300Z"
    }
   },
   "id": "acd9e45cb3aea9bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Лемматизация"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48790606ab1428d1"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this this\n",
      "product product\n",
      "integrates integrate\n",
      "both both\n",
      "libraries library\n",
      "for for\n",
      "downloading download\n",
      "and and\n",
      "applying apply\n",
      "patches patch\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_en(u'this product integrates both libraries for downloading and applying patches')\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:20:29.352065500Z",
     "start_time": "2023-11-26T20:20:29.313062Z"
    }
   },
   "id": "fae4813aa546e8d6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#!pip install tabulate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:20:31.947523Z",
     "start_time": "2023-11-26T20:20:31.924167400Z"
    }
   },
   "id": "41e2674d3f51c1a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:20:32.576469800Z",
     "start_time": "2023-11-26T20:20:32.553296900Z"
    }
   },
   "id": "a2e8dd8023abe73e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "исх          лемма\n",
      "-----------  -----------\n",
      "этот         этот\n",
      "продукт      продукт\n",
      "объединяет   объединять\n",
      "обе          оба\n",
      "библиотеки   библиотека\n",
      "для          для\n",
      "загрузки     загрузка\n",
      "и            и\n",
      "применения   применение\n",
      "исправлений  исправление\n",
      ".            .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_ru(u'этот продукт объединяет обе библиотеки для загрузки и применения исправлений.')\n",
    "print(tabulate([[token.text, token.lemma_] for token in doc], headers=['исх', 'лемма']))\n",
    "# for token in doc:\n",
    "#     print(token.text,'\\t', token.lemma_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:20:33.068554Z",
     "start_time": "2023-11-26T20:20:33.035996700Z"
    }
   },
   "id": "1bec63cde7a0965e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Использование лемматизации для распознавания смысла"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96f82c2455c03353"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH, LEMMA, NORM"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:30:31.172523500Z",
     "start_time": "2023-11-26T20:30:31.159116700Z"
    }
   },
   "id": "26ce233bef79cca5"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e9e8f665af338a77"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'flying', 'to', 'Frisco']\n",
      "['I', 'be', 'fly', 'to', 'San Francisco']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_en(u'I am flying to Frisco')\n",
    "print([w.text for w in doc])\n",
    "\n",
    "nlp_en.get_pipe(\"attribute_ruler\").add([[{\"TEXT\": \"Frisco\"}]], {\"LEMMA\": \"San Francisco\"})\n",
    "# special_case = [{ORTH: u'Frisco', LEMMA: u'San Francisco'}]\n",
    "# nlp_en.tokenizer.add_special_case(u'Frisco', special_case)\n",
    "print([w.lemma_ for w in nlp_en(u'I am flying to Frisco')])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T08:21:26.010762Z",
     "start_time": "2023-11-27T08:21:25.987242200Z"
    }
   },
   "id": "d70448a2750fc687"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Я', 'лечу', 'в', 'Питер']\n",
      "['я', 'лечу', 'в', 'Санкт - Петербург']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_ru(u'Я лечу в Питер')\n",
    "print([w.text for w in doc])\n",
    "\n",
    "nlp_ru.get_pipe(\"attribute_ruler\").add([[{\"TEXT\": \"Питер\"}]], {\"LEMMA\": \"Санкт - Петербург\"})\n",
    "print([w.lemma_ for w in nlp_ru(u'Я лечу в Питер')])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:04:43.237035600Z",
     "start_time": "2023-11-27T10:04:43.207077Z"
    }
   },
   "id": "7f61650e2cd09231"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Поиск соответствующих глаголов с помощью тегов частей речи"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9e690c68c370a04"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flying']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_en(u'I have flown to LA. Now I am flying to Frisco.')\n",
    "print([w.text for w in doc if w.tag_== 'VBG' or w.tag_== 'VB'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T15:00:35.090604200Z",
     "start_time": "2023-11-27T15:00:35.072295300Z"
    }
   },
   "id": "a40b0afaf0ed15e5"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRP', 'VBP', 'VBN', 'IN', 'NNP', '.', 'RB', 'PRP', 'VBP', 'VBG', 'IN', 'NNP', '.']\n"
     ]
    }
   ],
   "source": [
    "print([w.tag_ for w in doc ])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T15:00:35.495625400Z",
     "start_time": "2023-11-27T15:00:35.480890700Z"
    }
   },
   "id": "ca8fbf80c1a9c17f"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['летал', 'лечу']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_ru(u'Я летал в Москву. Сейчас я лечу в Питер')\n",
    "print([w.text for w in doc if w.tag_== 'VERB'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T15:00:50.624132600Z",
     "start_time": "2023-11-27T15:00:50.597388800Z"
    }
   },
   "id": "37629376094362dc"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRON', 'VERB', 'ADP', 'PROPN', 'PUNCT', 'ADV', 'PRON', 'VERB', 'ADP', 'PROPN']\n"
     ]
    }
   ],
   "source": [
    "print([w.tag_ for w in doc ])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T15:00:50.959704500Z",
     "start_time": "2023-11-27T15:00:50.935592500Z"
    }
   },
   "id": "e69f93987db59514"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e14d08dab4cb75f6"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я PRON nsubj\n",
      "летал VERB ROOT\n",
      "в ADP case\n",
      "Москву PROPN obl\n",
      ". PUNCT punct\n",
      "Сейчас ADV advmod\n",
      "я PRON nsubj\n",
      "лечу VERB ROOT\n",
      "в ADP case\n",
      "Питер PROPN obl\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T15:28:36.485972600Z",
     "start_time": "2023-11-27T15:28:36.461173500Z"
    }
   },
   "id": "79bb56183813d43d"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  -----  ----------\n",
      "этот         DET    det\n",
      "продукт      NOUN   nsubj\n",
      "объединяет   VERB   ROOT\n",
      "обе          NUM    nummod:gov\n",
      "библиотеки   NOUN   obj\n",
      "для          ADP    case\n",
      "загрузки     NOUN   nmod\n",
      "и            CCONJ  cc\n",
      "применения   NOUN   conj\n",
      "исправлений  NOUN   nmod\n",
      ".            PUNCT  punct\n",
      "-----------  -----  ----------\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_ru(u'этот продукт объединяет обе библиотеки для загрузки и применения исправлений.')\n",
    "print(tabulate([[token.text, token.pos_, token.dep_] for token in doc]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T15:30:22.800522700Z",
     "start_time": "2023-11-27T15:30:22.670501100Z"
    }
   },
   "id": "6d660939cb3477d9"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------  -----  ------\n",
      "Я       PRON   nsubj\n",
      "летал   VERB   ROOT\n",
      "в       ADP    case\n",
      "Москву  PROPN  obl\n",
      ".       PUNCT  punct\n",
      "Сейчас  ADV    advmod\n",
      "я       PRON   nsubj\n",
      "лечу    VERB   ROOT\n",
      "в       ADP    case\n",
      "Питер   PROPN  obl\n",
      "------  -----  ------\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_ru(u'Я летал в Москву. Сейчас я лечу в Питер')\n",
    "print(tabulate([[token.text, token.pos_, token.dep_] for token in doc]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:46:39.942331900Z",
     "start_time": "2023-11-27T19:46:38.838517900Z"
    }
   },
   "id": "883a093b05cb1d8a"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------  ------  ------\n",
      "летал   nsubj   Я\n",
      "летал   ROOT    летал\n",
      "Москву  case    в\n",
      "летал   obl     Москву\n",
      "летал   punct   .\n",
      "лечу    advmod  Сейчас\n",
      "лечу    nsubj   я\n",
      "лечу    ROOT    лечу\n",
      "Питер   case    в\n",
      "лечу    obl     Питер\n",
      "------  ------  ------\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[token.head.text, token.dep_, token.text]  for token in doc]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:46:41.085976800Z",
     "start_time": "2023-11-27T19:46:41.070337500Z"
    }
   },
   "id": "80020e21c271cca5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В этом смысле многообещающе выглядят токены, маркированные\n",
    "метками зависимостей ROOT и pobj (в данном примере они играют\n",
    "ключевую роль в распознавании намерения). Как упоминалось ранее,\n",
    "метка ROOT обозначает смысловой глагол предложения, а pobj в этом\n",
    "примере отмечает сущность, которая в сочетании с глаголом резюми-\n",
    "рует смысл всего высказывания.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31f107672f24a82f"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['летал', 'Москву']\n",
      "['лечу', 'Питер']\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print([w.text for w in sent if w.dep_ == 'ROOT' or w.dep_ == 'obl'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T20:45:41.524921200Z",
     "start_time": "2023-11-27T20:45:41.420596100Z"
    }
   },
   "id": "8735af52bbbeb206"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "doc = nlp_en(u'I have flown to LA. Now I am flying to Frisco.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T20:49:21.757017600Z",
     "start_time": "2023-11-27T20:49:19.998845300Z"
    }
   },
   "id": "e9db37afa97f1391"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flown', 'LA']\n",
      "['flying', 'Frisco']\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print([w.text for w in sent if w.dep_ == 'ROOT' or w.dep_ == 'pobj'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T20:49:39.895391100Z",
     "start_time": "2023-11-27T20:49:39.861602200Z"
    }
   },
   "id": "76325e7f8d251b2f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Распознавание именованных сущностей"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de2fea4ee4e8cad4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LA GPE\n",
      "Frisco ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_en(u'I have flown to LA. Now I am flying to Frisco.')\n",
    "for token in doc:\n",
    "    if token.ent_type != 0:\n",
    "        print(token.text, token.ent_type_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:45:16.144032800Z",
     "start_time": "2023-11-28T17:45:16.117103800Z"
    }
   },
   "id": "a02d55fee7f2eb9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сибири LOC\n",
      "Питер LOC\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_ru(u'Я живу в Сибири. Сейчас я лечу в Питер')\n",
    "for token in doc:\n",
    "    if token.ent_type != 0:\n",
    "        print(token.text, token.ent_type_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:46:22.040447100Z",
     "start_time": "2023-11-28T17:46:22.007493800Z"
    }
   },
   "id": "e7564a55b383381f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "948d7a74cb0ce92"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
